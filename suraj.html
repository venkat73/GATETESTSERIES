<html>
<body>
<br/><br/>

<p><b>Q.1.</b> Consider the set of processes with arrival time (in milliseconds). CPU burst time (in milliseconds) and priority (0 is the highest priority) shown below. None of the processes have I/O burst time.<b>(GATE 2017 CS02)</b></p>
<p><table border="1">
<thead>
<tr>
<th>Process</th><th>Arrival Time</th><th>Burst time</th><th>Priority</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td><td>0</td><td>11</td><td>2</td>
</tr>
<tr>
<td>P2</td><td>5</td><td>28</td><td>0</td>
</tr>
<tr>
<td>P3</td><td>12</td><td>2</td><td>3</td>
</tr>
<tr>
<td>P4</td><td>2</td><td>10</td><td>1</td>
</tr>
<tr>
<td>P5</td><td>9</td><td>16</td><td>4</td>
</tr>
</tbody>
</table>
</p>

<p>The average waiting time (in milli seconds) of all the process using premtive priority scheduling algorithm is ______</p>
<ol>
<li><p>29.0</p></li>
<li><p>28.0</p></li>
<li><p>27.0</p></li>
<li><p>30.0</p></li>
</ol>
<p><b>Ans . </b> 29.0 </p>
<br/>
<p>Solution to the above problem is given below:</p>
<img src="images/solution.jpg"
  alt="priority encoder"
  width="700"
  height="500"
  layout="responsive"
  class="m1">
  <noscript>
    <img src="images/solution.jpg" width="700" height="500" alt="priority encoder"> 
  </noscript>
</img><br/>

<br/><br/>

<p><b>Q.2.</b> Consider the following system snapsnot <b>(GATE 2017 CS02)</b></p>
<p><table border="8">
<thead>
<tr>
<th>Process</th><th>Currently allocation</th><th>Maximum</th><th>Need</th><th>Available</th>
</tr>
</thead>
<tbody>
<tr>
<td>P0</td><td>0 1 0</td><td>7 5 3</td><td>7 4 3<td>2 3 0</td>
</tr>
<tr>
<td>P1</td><td>3 0 2</td><td>3 2 2</td><td>0 2 0</td>
</tr>
<tr>
<td>P2</td><td>3 0 2</td><td>9 0 2</td><td>6 0 0</td>
</tr>
<tr>
<td>P3</td><td>2 1 1</td><td>2 2 2</td><td>0 1 1</td>
</tr>
<tr>
<td>P4</td><td>0 0 2</td><td>4 3 3</td><td>4 3 1</td>
</tr>
</tbody>
</table>
</p>
<p>Which of the following is a safe sequence?</p>
<ol>
<li><p>P1,P3,P0,P4,P2</p></li>
<li><p>P3,P1,P4,P0,P2</p></li>
<li><p>P3,P4,P1,P0,P2</p></li>
<li><p>All of these</p></li>
</ol>
<p><b>Ans . </b>(1).P1,P3,P0,P4,P2</p>
<p>Solution to the above problem is given below:</p>
<p>A safe sequence will not start with P3 here because, P3 needs 1 resource of C, but for C, none is available at present. If P1 completes & releases all its currently held resources, then P3 can proceed. So here P1,P3,P0,P4,P2 is a safe sequence</p>
<br/><br/>

<p><b>Q.3.</b> A system shares 9 tape drives. The current allocation and maximum requirement of tape drives for 3 processes are shown below:<b>(GATE 2017 CS02)</b></p>
<p><table border="8">
<thead>
<tr>
<th>Process</th><th>Current allocation</th><th>Maximum requirement</th>
</thead>
<tbody>
<tr>
<td>P1</td><td>3</td><td>7</td>
</tr>
<tr>
<td>P2</td><td>1</td><td>6</td>
</tr>
<tr>
<td>P3</td><td>3</td><td>5</td>
</tr>
</tbody>
</table>
</p>
<p>Which of the following best describes the current state of the system?</p>
<ol>
<li><p>Safe, Deadlocked</p></li>
<li><p>Safe, Not Deadlocked</p></li>
<li><p>Not Safe, Deadlocked</p></li>
<li><p>Not Safe, Not Deadlocked</p></li>
</ol>
<p><b>Ans . </b>(2).Safe, Not Deadlocked</p>
<p>Solution to the above problem is given below:</p>
<img src="images/solution2.png"
  alt="priority encoder"
  width="700"
  height="500"
  layout="responsive"
  class="m1">
  <noscript>
    <img src="images/solution2.png" width="700" height="500" alt="priority encoder"> 
  </noscript>
</img><br/>
<br/><br/>

<p><b>Q.4.</b>Consider the following CPU processes with arrival times (in milliseconds) and length of CPU bursts (in milliseconds) as given below:<b>(GATE 2017 CS01)</b></p>
<p><table border="1">
<thead>
<tr>
<th>Process</th><th>Arrival Time</th><th>Burst time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td><td>0</td><td>7</td>
</tr>
<tr>
<td>P2</td><td>3</td><td>3</td>
</tr>
<tr>
<td>P3</td><td>5</td><td>5</td>
</tr>
<tr>
<td>P4</td><td>6</td><td>2</td>
</tr>

</tbody>
</table>
</p>

<p>If the pre-emptive shortest remaining time first scheduling algorithm is used to schedule the processes, then the average waiting time across all processes is _______ milliseconds. </p>
<ol>
<li><p>1</p></li>
<li><p>2</p></li>
<li><p>3</p></li>
<li><p>4</p></li>
</ol>
<p><b>Ans . </b>3</p>
<br/>
<p>Solution to the above problem is given below:</p>
<p>Given, with arrival time and burst time: </p>
<img src="images/solution3.png"
  alt="priority encoder"
  width="700"
  height="500"
  layout="responsive"
  class="m1">
  <noscript>
    <img src="images/solution3.png" width="700" height="500" alt="priority encoder"> 
  </noscript>
</img><br/>
<p>Using (preemptive) shortest remaining time first algorithm, gantt chart is:</p>
<img src="images/solution4.png"
  alt="priority encoder"
  width="700"
  height="500"
  layout="responsive"
  class="m1">
  <noscript>
    <img src="images/solution4.png" width="700" height="500" alt="priority encoder"> 
  </noscript>
</img><br/>
<p> Therefore,
Average waiting time = ( 5 + 0 + 7 + 0 ) / 4 = 12 / 4 = 3</p>

<br/><br/>

<p><b>Q.5.</b> A multithreaded program P executes with xx number of threads and uses yy number of locks for ensuring mutual exclusion while operating on shared memory locations. All locks in the program are non-reentrant, i.e., if a thread holds a lock ll, then it cannot re-acquire lock ll without releasing it. If a thread is unable to acquire a lock, it blocks until the lock becomes available. The minimum value of xx and the minimum value of yy together for which execution of P can result in a deadlock are:<b>(GATE 2017 CS01)</b></p>

<ol>
<li><p>xx = 1, yy = 2</p></li>
<li><p>xx = 2, yy = 1</p></li>
<li><p>xx = 2, yy = 2</p></li>
<li><p>xx = 1, yy = 1</p></li>
</ol>
<p><b>Ans . </b>(4).xx = 1, yy = 1</p>
<p>Solution:</p>
<p> If we see definition of reentrant Lock :

In computer science, the reentrant mutex (recursive mutex, recursive lock) is particular type of mutual exclusion (mutex) device that may be locked multiple times by the same process/thread, without causing a deadlock. https://en.wikipedia.org/wiki/Reentrant_mutex

A ReentrantLock is owned by the thread last successfully locking, but not yet unlocking it. A thread invoking lock will return, successfully acquiring the lock, when the lock is not owned by another thread. The method will return immediately if the current thread already owns the lock https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/locks/ReentrantLock.html

I think Reentrant property is provided, so that a process who owns a lock , can accuire same lock multiple times. Here it is non-reentrant as given, process cant own same lock multiple times, so if process tries to accuire already owned lock, will get blocked , and deadlock will happen.

So answer is (4)th option </p>
<br/><br/>

<p><b>Q.6.</b> In a file allocation system which of the following allocation schemes can be used if no external fragementation is allowed?<b>(GATE 2017 CS02)</b>
<br/>
<p>I.Contiguous</p>
<p>II.Linked</p>
III.Indexed</p>

<ol>
<li><p>I and III only</p></li>
<li><p>II only</p></li>
<li><p>III only</p></li>
<li><p>II and III only</p></li>
</ol>
<p><b>Ans . </b>(4).II and III only</p>
<p>Solution:</p>
<p>In contiguous allocation, there is a possibility of external fragementation.
So, the correct option is (4)</p>
<br/><br/>

<p><b>Q.7.</b>Consider an arbitrary set of CPU-bound processes with unequal CPU burst lengths
submitted at the same time to a computer system. Which one of the following process scheduling algorithms would minimize the average waiting time in the ready queue?<b>(GATE 2016 CS01)</b>
<ol>
<li><p>Shortest remaining time first</p></li>
<li><p>Round-robin with time quantum less than the shortest CPU burst</p></li>
<li><p>Uniform random</p></li>
<li><p>Highest priority first with priority proportional to CPU burst length</p></li>
</ol>
<p><b>Ans . </b>(1).Shortest remaining time first</p>
<p>Solution:</p>
<p>Turnaround time is the total time taken by the process between starting and the completion and waiting time is the time for which process is ready to run but not executed by CPU scheduler. As we know, in all CPU Scheduling algorithms, shortest job first is optimal i.ie. it gives minimum turn round time, minimum average waiting time and high throughput and the most important thing is that shortest remaining time first is the pre-emptive version of shortest job first. shortest remaining time first scheduling algorithm may lead to starvation because If the short processes are added to the cpu scheduler continuously then the currently running process will never be able to execute as they will get pre-empted but here all the processes are arrived at same time so there will be no issue such as starvation.
So, the answer is Shortest remaining time first, which is answer (1).</p>
<br/><br/>


<p><b>Q.8.</b>Consider a disk queue with requests for I/O to blocks on cylinders 47, 38, 121, 191, 87, 11, 92, 10. The C-LOOK scheduling algorithm is used. The head is initially at cylinder number 63, moving towards larger cylinder numbers on its servicing pass. The cylinders are numbered from 0 to 199. The total head movement (in number of cylinders) incurred while servicing these requests is:_________<b>(GATE 2016 CS01)</b>
<ol>
<li><p>346</p></li>
<li><p>165</p></li>
<li><p>154</p></li>
<li><p>173</p></li>
</ol>
<p><b>Ans . </b>(2).165</p>
<p>Solution:</p>
<p>The head movement would be:
<br/>
63 => 87 24 movements</br>
87 => 92 5 movements</br>
92 => 121 29 movements</br>
121 => 191 70 movements</br>
191 --> 10 0 movement</br>
10 => 11 1 movement</br>
11 => 38 27 movements</br>
38 => 47 9 movements</br>
Total head movements = 165
</p>
<br/><br/>

<p><b>Q.9.</b>Consider the following proposed solution for the critical section problem. There are n processes: P0 …Pn-1. In the code, function pmax returns an integer not smaller than any of its arguments. For all i, t[i] is initialized to zero.<b>(GATE 2016 CS02)</b>
<p>Code for Pi:<br/>
do {<br/>
c[i]=1; t[i] = pmax(t[0],...,t[n-1])+1; c[i]=0;<br/>
for every j 6= i in {0,...,n-1} {<br/>
while (c[j]);<br/>
while (t[j] != 0 && t[j]<=t[i]);<br/>
}<br/>
Critical Section;<br/>
t[i]=0;<br/>
Remainder Section;<br/>
} while (true);<br/></p>
<p>Which one of the following is TRUE about the above solution?</p>
<ol>
<li><p>At most one process can be in the critical section at any time</p></li>
<li><p>The bounded wait condition is satisfied</p></li>
<li><p>The progress condition is satisfied</p></li>
<li><p>It cannot cause a deadlock</p></li>
</ol>
<p><b>Ans . </b>(1).At most one process can be in the critical section at any time</p>
<p>Solution:</p>
<p>Mutual exclusion  is satisfied:</br>
All other processes j started before i must have value (i.e. t[j]) 
less than the value of process i (i.e. t[i])  as function pMax() 
return a integer not smaller  than any of its arguments. So if anyone 
out of the processes j have positive value will be executing in its 
critical section as long as the condition t[j] > 0 && t[j] <= t[i] within 
while will persist. And when  this j process comes out of its critical 
section, it sets t[j] = 0;  and next process will be selected in for loop.
So when i process reaches to its critical section none of the  processes j 
which started earlier before process i  is in its critical section. This 
ensure that only one process is executing its critical section at a time.<br/><br/>
Deadlock and progress are  not satisfied:<br/>  
while (t[j] != 0 && t[j] <=t[i]); because of this condition deadlock is 
possible when value of j process becomes equals to the value of process i 
(i.e t[j] == t[i]).  because of the deadlock progess is also not possible 
(i.e. Progess == no deadlock) as no one process is able to make progress  
by stoping other process.<br/><br/>
Bounded waiting is also not satisfied:<br/>
In this case both deadlock and bounded waiting to be arising from the same 
reason as if t[j] == t[i] is possible then starvation is possible means 
infinite waiting.  
</p>
<br/><br/>

<p><b>Q.10.</b>Consider the following processes, with the arrival time and the length of the CPU burst given
in milliseconds. The scheduling algorithm used is preemptive shortest remaining-time first.<b>(GATE 2016 CS02)</b></p>
<p><table border="1">
<thead>
<tr>
<th>Process</th><th>Arrival Time</th><th>Burst time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td><td>0</td><td>10</td>
</tr>
<tr>
<td>P2</td><td>3</td><td>6</td>
</tr>
<tr>
<td>P3</td><td>7</td><td>1</td>
</tr>
<tr>
<td>P4</td><td>8</td><td>3</td>
</tr>
</tbody>
</table>
</p>

<p>The average turn around time of these processes is __________ milliseconds.</p>
<ol>
<li><p>8.25</p></li>
<li><p>10.25</p></li>
<li><p>6.35</p></li>
<li><p>4.25</p></li>
</ol>
<p><b>Ans . </b>8.25</p>
<br/>
<p>Solution to the above problem is given below:</p>
<img src="images/solution5.jpg"
  alt="priority encoder"
  width="700"
  height="500"
  layout="responsive"
  class="m1">
  <noscript>
    <img src="images/solution5.jpg" width="700" height="500" alt="priority encoder"> 
  </noscript>
</img><br/>
<p>PreEmptive Shortest Remaining time first scheduling, i.e. that processes will be scheduled on the CPU which will be having least remaining burst time( required time at the CPU).

The processes are scheduled and executed as given in the above Gantt chart.</P>
<p>Turn Around Time(TAT) = Completion Time(CT) – Arrival Time(AT)

TAT for P1 = 20 – 0 = 20

TAT for P2 = 10 – 3 = 7

TAT for P3 = 8- 7 = 1

TAT for P4 = 13 – 8 = 5

Hence, Average TAT = Total TAT of all the processes / no of processes = ( 20 + 7 + 1 + 5 ) / 4 = 33 / 4 = 8.25
 
Thus, (1) is the correct choice.
</p>

<br/><br/>

<p><b>Q.11.</b>Consider the following two-process synchronization solution<b>(GATE 2016 CS02)</b></p>
<img src="images/solution6.jpg">
<p>The shared variable turn is initialized to zero. Which one of the following is TRUE?</p>
<ol>
<li><p>This is a correct two-process synchronization solution.</p></li>
<li><p>This solution violates mutual exclusion requirement.</p></li>
<li><p>This solution violates progress requirement.</p></li>
<li><p>This solution violates bounded wait requirement.</p></li>
</ol>
<p><b>Ans . </b>(3).This solution violates progress requirement.</p>
<p>Solution:</p>
<p>Mutual exclusion  is satisfied:</br>
Process P0 and P1 could not have successfully executed their while 
statements at the same time as value of ‘turn’ can either be 0 or 1 
but can’t be both at the same time. Lets say, when process P0 executing 
its while statements with the condition “turn == 1”, So this condition 
will persist as long as process P1 is executing its critical section. And 
when P1 comes out from its critical section it changes the value of  ‘turn’ 
to 0 in exit section and because of that time P0 comes out from the its while 
loop and enters into its critical section. Therefore only one process is 
able to execute its critical section at a time.<br/><br/>
It also satisfies bounded waiting:<br/>  
It is limit on number of times that other process is allowed to enter its
 critical section after a process has made a request to enter its critical 
section and before that request is granted. Lets say, P0 wishes to enter into
 its critical section, it will definitely get a chance to enter into its critical
 section after at most one entry made by p1 as after executing its critical section
 it will set ‘turn’ to 0 (zero). And vice-versa (strict alteration).<br/><br/>
Progess is also not satisfied:<br/>
Because of strict alternation no process can stop other process from entering into 
its critical section.
</p>
<br/><br/>

<p><b>Q.12.</b>Consider a non-negative counting semaphore S. The operation P(S) decrements S, and V(S) increments S. During an execution, 20 P(S) operations and 12 V(S) operations are issued in some order. The largest initial value of S for which at least one P(S) operation will remain blocked is ________.<b>(GATE 2016 CS02)</b>
<ol>
<li><p>7</p></li>
<li><p>8</p></li>
<li><p>9</p></li>
<li><p>10</p></li>
</ol>
<p><b>Ans . </b>(1).7</p>
<p>Explanation:</p>
<p> 20-7 -> 13 will be in blocked state, when we perform 12 V(S) operation makes 12 more process to get chance for execution from blocked state. So one process will be left in the queue (blocked state) here I have considered that if a process is in under CS then it not get blocked by other process.</p>
<br/><br/>

<p><b>Q.13.</b>Consider a uniprocessor system executing three tasks T1, T2 and T3, each of which is composed of an infinite sequence of jobs (or instances) which arrive periodically at intervals of 3, 7 and 20 milliseconds, respectively. The priority of each task is the inverse of its period and the available tasks are scheduled in order of priority, with the highest priority task scheduled first. Each instance of T1, T2 and T3 requires an execution time of 1, 2 and 4 milliseconds, respectively. Given that all tasks initially arrive at the beginning of the 1st milliseconds and task preemptions are allowed, the first instance of T3 completes its execution at the end of ______________ milliseconds.<b>(GATE 2015 CS01)</b>
<ol>
<li><p>5</p></li>
<li><p>10</p></li>
<li><p>12</p></li>
<li><p>15</p></li>
</ol>
<p><b>Ans . </b>(3).12</p>
<p>Explanation:</p>
<p>Periods of T1, T2 and T3 are 3ms, 7ms and 20ms

Since priority is inverse of period, T1 is the highest 
priority task, then T2 and finally T3

Every instance of T1 requires 1ms, that of T2 requires 
2ms and that of T3 requires 4ms

Initially all T1, T2 and T3 are ready to get processor, 
T1 is preferred

Second instances of T1, T2, and T3 shall arrive at 3, 7, 
and 20 respectively.

Third instance of T1, T2 and T3 shall arrive at 6, 14, 
and 49 respectively.<br/> 
<table border="1">
<thead>
<th>Time-Interval</th><th>Tasks</th>
</thead>
<tbody>
<tr>
<th>0-1</th><th>T1</th>
</tr>
<tr>
<th>1-2</th><th>T2</th>
</tr>
<tr>
<th>2-3</th><th>T2</th>
</tr>    
<tr>
<th>3-4</th><th>T1  [Second Instance of T1 arrives] </th>
</tr>   
<tr>
<th>4-5</th><th>T3</th>
</tr> 
<tr>
<th>5-6</th><th>T3</th>
</tr>  
<tr>
<th>6-7</th><th>T1  [Third Instance of T1 arrives]  [Therefore T3 is preempted]  </th>
</tr> 
<tr>
<th>7-8</th><th>T2  [Second instance of T2 arrives]</th>
</tr> 
<tr>
<th>8-9</th><th>T2</th>
</tr>                           
<tr>
<th>9-10</th><th>T1[Fourth Instance of T1 arrives] </th>
</tr>
<tr>
<th>10-11</th><th>T3</th>
</tr>
<tr>
<th>11-12</th><th>T3 [First Instance of T3 completed]</th>
</tr>
</tbody>
</table>                            
</p>
<br/><br/>


<p><b>Q.14.</b>Consider a disk pack with a seek time of 4 milliseconds and rotational speed of 10000 rotations per minute (RPM). It has 600 sectors per track and each sector can store 512 bytes of data. Consider a file stored in the disk. The file contains 2000 sectors. Assume that every sector access necessitates a seek, and the average rotational latency for accessing each sector is half of the time for one complete rotation. The total time (in milliseconds) needed to read the entire file is _________.<b>(GATE 2015 CS01)</b>
<ol>
<li><p>14020</p></li>
<li><p>14000</p></li>
<li><p>25030</p></li>
<li><p>15000</p></li>
</ol>
<p><b>Ans . </b>(1).14020</p>
<p>Explanation:</p>
<p>Seek time (given) = 4ms</br>

RPM = 10000 rotation in 1 min [60 sec]</br>
So, 1 rotation will be =60/10000 =6ms [rotation speed]</br>
Rotation latency= 1/2 * 6ms=3ms</br>
# To access a file, </br>
  total time includes =seek time + rot. latency +transfer time</br>
TO calc. transfer time, find transfer rate</br>

Transfer rate = bytes on track /rotation speed</br>
so, transfer rate = 600*512/6ms =51200 B/ms</br>

transfer time= total bytes to be transferred/ transfer rate</br>
so, Transfer time =2000*512/51200 = 20ms</br>

Given as each sector requires seek tim + rot. latency</br>
= 4ms+3ms =7ms</br>

Total 2000 sector takes = 2000*7 ms =14000 ms</br>
To read entire file ,total time = 14000 + 20(transfer time)
                                = 14020 ms</p>
<br/><br/>

<p><b>Q.15.</b>Suppose the following disk request sequence (track numbers) for a disk with 100 tracks is given: 45, 20, 90, 10, 50, 60, 80, 25, 70. Assume that the initial position of the R/W head is on track 50. The additional distance that will be traversed by the R/W head when the Shortest Seek Time First (SSTF) algorithm is used compared to the SCAN (Elevator) algorithm (assuming that SCAN algorithm moves towards 100 when it starts execution) is _________ tracks<b>(GATE 2015 CS01)</b>
<ol>
<li><p>8</p></li>
<li><p>9</p></li>
<li><p>10</p></li>
<li><p>11</p></li>
</ol>
<p><b>Ans . </b>(3).10</p>
<p>Explanation:</p>
<p>
In Shortest seek first (SSTF), closest request to the current position of the head, and then services that request next.</br>

In SCAN (or Elevator) algorithm, requests are serviced only in the current direction of arm movement until the arm reaches the edge of the disk. When this happens, the direction of the arm reverses, and the requests that were remaining in the opposite direction are serviced, and so on.</br>

Given a disk with 100 tracks </br>

And Sequence 45, 20, 90, 10, 50, 60, 80, 25, 70.</br>

Initial position of the R/W head is on track 50.</br>

In SSTF, requests are served as following:<br/> 
<table border="1">
<thead>
<th>Next served</th><th>Distance travelled</th>
</thead>
<tbody>
<tr>
<th>50</th><th>0</th>
</tr>
<tr>
<th>45</th><th>5</th>
</tr>
<tr>
<th>60</th><th>15</th>
</tr>    
<tr>
<th>70</th><th>10</th>
</tr>   
<tr>
<th>80</th><th>10</th>
</tr> 
<tr>
<th>90</th><th>10</th>
</tr>  
<tr>
<th>25</th><th>65</th>
</tr> 
<tr>
<th>20</th><th>5</th>
</tr> 
<tr>
<th>10</th><th>10</th>
</tr>                           
</tbody>
<tfoot>
<th>Total distance</th><th>=130</th>
</tfoot>
</table>
</br>If Simple SCAN is used, requests are served as following:</br></br>
<table border="1">
<thead>
<th>Next served</th><th>Distance travelled</th>
</thead>
<tbody>
<tr>
<th>50</th><th>0</th>
</tr>
<tr>
<th>60</th><th>10</th>
</tr>
<tr>
<th>70</th><th>10</th>
</tr>    
<tr>
<th>80</th><th>10</th>
</tr>   
<tr>
<th>90</th><th>10</th>
</tr> 
<tr>
<th>45</th><th>65(Disk arm goes to 100, then 45)</th>
</tr>  
<tr>
<th>25</th><th>20</th>
</tr> 
<tr>
<th>20</th><th>5</th>
</tr> 
<tr>
<th>10</th><th>10</th>
</tr>                           
</tbody>
<tfoot>
<th>Total distance</th><th>=140</th>
</tfoot>
</table>
</br>Less Distance traveled in SSTF = 130 - 140 =  10</br> 
</br>Therefore, it is not additional but it is less distance traversed by SSTF than SCAN.                            
</p>
<br/><br/>
<p><b>Q.16.</b>Consider a typical disk that rotates at 15000 rotations per minute (RPM) and has a transfer rate of 50 × 106 bytes/sec. If the average seek time of the disk is twice the average rotational delay and the controller’s transfer time is 10 times the disk transfer time, the average time (in milliseconds) to read or write a 512 byte sector of the disk is _____________<b>(GATE 2015 CS02)</b>
<p><b>Ans:</b>6.1</p>
<p>Explanation:</p>
<p>Disk latency = Seek Time + Rotation Time + Transfer Time + Controller Overhead</br>
Seek Time? Depends no. tracks the arm moves and seek speed of disk</br>
Rotation Time? depends on rotational speed and how far the sector is from the head </br>
Transfer Time? depends on data rate (bandwidth) of disk (bit density) and the size of request</br>

Disk latency = Seek Time + Rotation Time + Transfer Time + Controller Overhead</br>

Average Rotational Time = (0.5)/(15000 / 60) = 2 miliseconds</br>
[On average half rotation is made]</br>

It is given that the average seek time is twice the average rotational delay</br>
So Avg. Seek Time =  2 * 2 = 4 miliseconds.</br>

Transfer Time = 512 / (50 × 106 bytes/sec)= 10.24 microseconds</br>

Given that controller time is 10 times the average transfer time</br>
Controller Overhead = 10 * 10.24 microseconds= 0.1 miliseconds</br>

Disk latency = Seek Time + Rotation Time + Transfer Time + Controller Overhead</br>
             = 4 + 2 + 10.24 * 10-3 + 0.1 miliseconds= 6.1 miliseconds</p>
<br/><br/>

<p><b>Q.17.</b>Consider the procedure below for the Producer-Consumer problem which uses semaphores(GATE 2014 CS02)</b></p>
<img src="images/solution7.png">
<p>Which one of the following is TRUE?</p>
<ol>
<li><p>The producer will be able to add an item to the buffer, but the consumer can never consume it.</p></li>
<li><p>The consumer will remove no more than one item from the buffer.</p></li>
<li><p>Deadlock occurs if the consumer succeeds in acquiring semaphore s when the buffer is empty.</p></li>
<li><p>The starting value for the semaphore n must be 1 and not 0 for deadlock-free operation.</p></li>
</ol>
<p><b>Ans:</b>(3).Deadlock occurs if the consumer succeeds in acquiring semaphore s when the buffer is empty.</p>
<p>Explanation:</p>
<p>Initially, there is no element in the buffer.</br>

Semaphore s = 1 and semaphore n = 0.</br>

We assume that initially control goes to the consumer when buffer is empty.</br>


semWait(s) decrements the value of semaphore ‘s’ . Now, s = 0 and semWait(n) decrements the value of semaphore ‘n’.</br>

Since, the value of semaphore ‘n’ becomes less than 0 , the control stucks in while loop of function semWait() and a deadlock arises.</br>

 
Thus, deadlock occurs if the consumer succeeds in acquiring semaphore s when the buffer is empty.</p>
<br/><br/>

<p><b>Q.18</b>Three processes A, B and C each execute a loop of 100 iterations. In each iteration of the loop, a process performs a single computation that requires tc CPU milliseconds and then initiates a single I/O operation that lasts for tio milliseconds. It is assumed that the computer where the processes execute has sufficient number of I/O devices and the OS of the computer assigns different I/O devices to each process. Also, the scheduling overhead of the OS is negligible. The processes have the following characteristics:(GATE 2014 CS02)</b></p>
<table>
<thead>
<th>Process id</th><th>tc</th><th>tio</th>
</thead>
<tbody>
<tr>
<th>A</th><th>100ms</th><th>500ms</th>
</tr>
<tr>
<th>B</th><th>350ms</th><th>500ms</th>
</tr>
<tr>
<th>C</th><th>200ms</th><th>500ms</th>
</tr>
</tbody>
</table>
<p>The processes A, B, and C are started at times 0, 5 and 10 milliseconds respectively, in a pure time sharing system (round robin scheduling) that uses a time slice of 50 milliseconds. The time in milliseconds at which process C would complete its first I/O operation is ___________.</p>
<ol>
<li><p>500</p></li>
<li><p>1000</p></li>
<li><p>2000</p></li>
<li><p>10000</p></li>
</ol>
<p><b>Ans:</b>(2).1000</p>
<p>Explanation:</p>
<p>There are three processes A, B and C that run in 
round robin manner with time slice of 50 ms.</br>

Processes atart at 0, 5 and 10 miliseconds.</br>

The processes are executed in below order</br>
A, B, C, A </br>
50 + 50 + 50 + 50 (200 ms passed)</br>

Now A has completed 100 ms of computations and 
goes for I/O now</br>

B, C, B, C, B, C</br>
50 + 50 + 50 + 50 + 50 + 50 (300 ms passed)</br>

C goes for i/o at 500ms and it needs 500ms to
finish the IO.</br>

So C would complete its first IO at 1000 ms</p>
<br/><br/>

<p><b>Q.19</b>Suppose a disk has 201 cylinders, numbered from 0 to 200. At some time the disk arm is at cylinder 100, and there is a queue of disk access requests for cylinders 30, 85, 90, 100, 105, 110, 135 and 145. If Shortest-Seek Time First (SSTF) is being used for scheduling the disk access, the request for cylinder 90 is serviced after servicing ____________ number of requests.(GATE 2014 CS01)</b></p>
<ol>
<li><p>1</p></li>
<li><p>2</p></li>
<li><p>3</p></li>
<li><p>4</p></li>
</ol>
<p><b>Ans:</b>(3).3</p>
<p>Explanation:</p>
<p> In Shortest-Seek-First algorithm, request closest to the current position of the disk arm and head is handled first.</br>

In this question, the arm is currently at cylinder number 100. Now the requests come in the queue order for cylinder numbers 30, 85, 90, 100, 105, 110, 135 and 145.</br>

The disk will service that request first whose cylinder number is closest to its arm. Hence 1st serviced request is for cylinder no 100 ( as the arm is itself pointing to it ), then 105, then 110, and then the arm comes to service request for cylinder 90. Hence before servicing request for cylinder 90, the disk would had serviced 3 requests.</br>

Hence option C.
</p>
<br/><br/>

<p><b>Q.20</b>Which one of the following is FALSE?(GATE 2014 CS01)</b></p>
<ol>
<li><p>User level threads are not scheduled by the kernel.</p></li>
<li><p>When a user level thread is blocked, all other threads of its process are blocked.</p></li>
<li><p>Context switching between user level threads is faster than context switching between kernel level threads.</p></li>
<li><p>Kernel level threads cannot share the code segment</p></li>
</ol>
<p><b>Ans:</b>(4).Kernel level threads cannot share the code segment</p>
<br/><br/>

<p><b>Q.21</b>Consider the following set of processes that need to be scheduled on a single CPU. All the times are given in milliseconds.(GATE 2014 CS01)</b></p>
<table>
<thead>
<th>Process name</th><th>Arrival time</th><th>Execution time</th>
</thead>
<tbody>
<tr>
<th>A</th><th>0</th><th>6</th>
</tr>
<tr>
<th>B</th><th>3</th><th>2</th>
</tr>
<tr>
<th>C</th><th>5</th><th>4</th>
</tr>
<tr>
<th>D</th><th>7</th><th>6</th>
</tr>
<tr>
<th>E</th><th>10</th><th>3</th>
</tr>
</tbody>
</table>
<p>Using the shortest remaining time first scheduling algorithm, the average process turnaround time (in msec) is ____________________.</p>
<ol>
<li><p>7.2</p></li>
<li><p>8</p></li>
<li><p>7</p></li>
<li><p>7.5</p></li>
</ol>
<p><b>Ans:</b>(1). <b>7.2</b></p>
<p>Explanation:</br>Turn around time of a process is total time between submission of the process and its completion.</br>Shortest remaining time (SRT) scheduling algorithm selects the process for execution which has the smallest amount of time remaining until completion.</p>
<p>Solution:</br>
Let the processes be A, ,C,D and E. These processes will be executed in following order. Gantt chart is as follows:
<img src="images/solution8.png">
</br>First 3 sec, A will run, then remaining time A=3, B=2,C=4,D=6,E=3 Now B will get chance to run for 2 sec, then remaining time. A=3, B=0,C=4,D=6,E=3</br>
Now A will get chance to run for 3 sec, then remaining time. A=0, B=0,C=4,D=6,E=3 By doing this way, you will get above gantt chart.</br>
Scheduling table:</br>
<img src="images/solution9.png">
</br>As we know, turn around time is total time between submission of the process and its completion. i.e turn around time=completion time-arrival time. i.e. TAT=CT-AT</br>
Turn around time of A = 8 (8-0)</br>
Turn around time of B = 2 (5-3)</br>
Turn around time of C = 7 (12-5)</br>
Turn around time of D = 14 (21-7)</br>
Turn around time of E = 5 (15-10)</br>
Average turn around time is (8+2+7+14+5)/5 = 7.2</br>
Answer is 7.2
</p>
<br/><br/>

<p><b>Q.22</b>A scheduling algorithm assigns priority proportional to the waiting time of a process. Every process starts with priority zero (the lowest priority). The scheduler re-evaluates the process priorities every T time units and decides the next process to schedule. Which one of the following is TRUE if the processes have no I/O operations and all arrive at time zero?(GATE 2013 CS01)</b></p>
<ol>
<li><p>This algorithm is equivalent to the first-come-first-serve algorithm</p></li>
<li><p>This algorithm is equivalent to the round-robin algorithm.</p></li>
<li><p>This algorithm is equivalent to the shortest-job-first algorithm..</p></li>
<li><p>This algorithm is equivalent to the shortest-remaining-time-first algorithm</p></li>
</ol>
<p><b>Ans:</b>(2).This algorithm is equivalent to the round-robin algorithm.</p>
<p>Explanation:</br>The scheduling algorithm works as round robin with quantum time equals to T.<br/> After a process’s turn comes and it has executed for T units, its waiting time becomes least and its turn comes again after every other process has got the token for T units.<br/></p>
<br/><br/>

<p><b>Q.23</b>Three concurrent processes X, Y, and Z execute three different code segments that access and update certain shared variables. Process X executes the P operation (i.e., wait) on semaphores a, b and c; process Y executes the P operation on semaphores b, c and d; process Z executes the P operation on semaphores c, d, and a before entering the respective code segments. After completing the execution of its code segment, each process invokes the V operation (i.e., signal) on its three semaphores. All semaphores are binary semaphores initialized to one. Which one of the following represents a deadlock-free order of invoking the P operations by the processes?(GATE 2013 CS01)</b></p>
<ol>
<li><p>X: P(a)P(b)P(c) Y: P(b)P(c)P(d) Z: P(c)P(d)P(a)</p></li>
<li><p>X: P(b)P(a)P(c) Y: P(b)P(c)P(d) Z: P(a)P(c)P(d)</p></li>
<li><p>X: P(b)P(a)P(c) Y: P(c)P(b)P(d) Z: P(a)P(c)P(d)</p></li>
<li><p>X: P(a)P(b)P(c) Y: P(c)P(b)P(d) Z: P(c)P(d)P(a)</p></li>
</ol>
<p><b>Ans:</b>(2).X: P(b)P(a)P(c) Y: P(b)P(c)P(d) Z: P(a)P(c)P(d)</p>
<p>Explanation:</p>
<p>Option A can cause deadlock. Imagine a situation process X has acquired a, process Y has acquired b and process Z has acquired c and d. There is circular wait now.</br>

Option C can also cause deadlock. Imagine a situation process X has acquired b, process Y has acquired c and process Z has acquired a. There is circular wait now.</br>

Option D can also cause deadlock. Imagine a situation process X has acquired a and b, process Y has acquired c. X and Y circularly waiting for each other.</br>
Consider option A) for example here all 3 processes are concurrent so X will get semaphore a, Y will get b and Z will get c, now X is blocked for b, Y is blocked for c, Z gets d and blocked for a. Thus it will lead to deadlock.<br/>

Similarly one can figure out that for B) completion order is Z,X then Y.<br/>
</p>
<br/><br/>

<p><b>Q.24</b>A shared variable x, initialized to zero, is operated on by four concurrent processes W, X, Y, Z as follows. Each of the processes W and X reads x from memory, increments by one, stores it to memory, and then terminates. Each of the processes Y and Z reads x from memory, decrements by two, stores it to memory, and then terminates. Each process before reading x invokes the P operation (i.e., wait) on a counting semaphore S and invokes the V operation (i.e., signal) on the semaphore S after storing x to memory. Semaphore S is initialized to two. What is the maximum possible value of x after all processes complete execution?(GATE 2013 CS01)</b></p>
<ol>
<li><p>-2</p></li>
<li><p>-1</p></li>
<li><p>1</p></li>
<li><p>2</p></li>
</ol>
<p><b>Ans:</b>(4).2</p>
<p>Explanation:</br>Background Explanation:<br/>
A critical section in which the process may be changing common variables, updating table, writing a file and perform another function. The important problem is that if one process is executing in its critical section, no other process is to be allowed to execute in its critical section. Each process much request permission to enter its critical section. A semaphore is a tool for synchronization and it is used to remove the critical section problem which is that no two processes can run simultaneously together so to remove this two signal operations are used named as wait and signal which is used to remove the mutual exclusion of the critical section. as an unsigned one of the most important synchronization primitives, because you can build many other Decrementing the semaphore is called acquiring or locking it, incrementing is called releasing or unlocking.<br/></p>
<p>Solution:</br>Since initial value of semaphore is 2, two processes can enter critical section at a time- this is bad and we can see why.
Say, X and Y be the processes.X increments x by 1 and Z decrements x by 2.<br/>Now, Z stores back and after this X stores back.<br/>So, final value of x is 1 and not -1 and two Signal operations make the semaphore value 2 again.<br/>So, now W and Z can also execute like this and the value of x can be 2 which is the maximum possible in any order of execution of the processes.<br/>(If the semaphore is initialized to 1, processed would execute correctly and we get the final
value of x as -2.)<br/>
Option (D) is the correct answer.<br/></p>
<br/><br/>

<p><b>Q.25</b>A process executes the code<br/>
 fork();<br/>
 fork();<br/>
 fork();<br/>
The total number of child processes created is(GATE 2012 CS01)</b></p>
<ol>
<li><p>3</p></li>
<li><p>4</p></li>
<li><p>7</p></li>
<li><p>8</p></li>
</ol>
<p><b>Ans:</b>(3).7</p>
<br/><br/>

<p><b>Q.26</b>Consider the 3 processes, P1, P2 and P3 shown in the table.(GATE 2012 CS01)</b></p>
<table>
<thead>
<th>Process</th><th>Arrival time</th><th>Time Units Required</th>
</thead>
<tbody>
<tr>
<th>P1</th><th>0</th><th>5</th>
</tr>
<tr>
<th>P2</th><th>1</th><th>7</th>
</tr>
<tr>
<th>P3</th><th>3</th><th>4</th>
</tr>
</tbody>
</table>
<p>The completion order of the 3 processes under the policies FCFS and RR2 (round robin scheduling with CPU quantum of 2 time units) are ____________________.</p>
<ol>
<li><p>FCFS: P1, P2, P3<br/>
 RR2: P1, P2, P3</p></li>
<li><p>FCFS: P1, P3, P2<br/>
 RR2: P1, P3, P2</p></li>
<li><p>FCFS: P1, P2, P3<br/>
 RR2: P1, P3, P2</p></li>
<li><p>FCFS: P1, P3, P2<br/> 
RR2: P1, P2, P3</p></li>
</ol>
<p><b>Ans:</b>(3).FCFS: P1, P2, P3<br/>
 RR2: P1, P3, P2</p>
<p>Explanation:</p>
<p>FCFS is clear.<br/>  
In RR, time slot is of 2 units.<br/>  
Processes are assigned in following order<br/>
p1, p2, p1, p3, p2, p1, p3, p2, p2<br/>.
This question involves the concept of ready queue.<br/>At t=2, p2 starts and p1 is sent to the ready queue and at t=3 p3 arrives so then the job p3 is queued in ready queue after p1. So at t=4, again p1 is executed then p3 is executed for first time at t=6.
</p>
<br/><br/>

<p><b>Q.27</b>A thread is usually defined as a ‘light weight process’ because an operating system (OS) maintains smaller data structures for a thread than for a process. In relation to this, which of the followings is TRUE?(GATE 2011 CS01)</b></p>
<ol>
<li><p>On per-thread basis, the OS maintains only CPU register state</p></li>
<li><p>The OS does not maintain a separate stack for each thread</p></li>
<li><p> On per-thread basis, the OS does not maintain virtual memory state</p></li>
<li><p>On per thread basis, the OS maintains only scheduling and accounting information.</p></li>
</ol>
<p><b>Ans:</b>(3).On per-thread basis, the OS does not maintain virtual memory state</p>
<p>Explanation:</p>
<p>Threads share address space of Process.<br/>Virtually memory is concerned with processes not with Threads.</p>
<br/><br/>

<p><b>Q.28</b>Let the page fault service time be 10ms in a computer with average memory access time being 20ns. If one page fault is generated for every 10^6 memory accesses, what is the effective access time for the memory?(GATE 2011 CS01)</b></p>
<ol>
<li><p>21ns</p></li>
<li><p>30ns</p></li>
<li><p>23ns</p></li>
<li><p>35ns</p></li>
</ol>
<p><b>Ans:</b>(2).30ns</p>
<p>Explanation:</p>
<p>Let P be the page fault rate
Effective Memory Access Time = p * (page fault service time) + 
                               (1 - p) * (Memory access time)<br/>
                             = ( 1/(10^6) )* 10 * (10^6) ns +
                               (1 - 1/(10^6)) * 20 ns<br/>
                             = 30 ns (approx)    </p>
<br/><br/>

<p><b>Q.29</b>An application loads 100 libraries at startup. Loading each library requires exactly one disk access. The seek time of the disk to a random location is given as 10ms. Rotational speed of disk is 6000rpm. If all 100 libraries are loaded from random locations on the disk, how long does it take to load all libraries? (The time to transfer data from the disk block once the head has been positioned at the start of the block may be neglected)(GATE 2011 CS01)</b></p>
<ol>
<li><p>0.50s</p></li>
<li><p>1.50s</p></li>
<li><p>1.25s</p></li>
<li><p>1.00s</p></li>
</ol>
<p><b>Ans:</b>(2).1.50s</p>
<p>Explanation:</p>
<p>Since transfer time can be neglected, the average access time is sum of average seek time and average rotational latency.<br/>Average seek time for a random location time is given as 10 ms.<br/>The average rotational latency is half of the time needed for complete rotation.<br/>It is given that 6000 rotations need 1 minute.<br/>So one rotation will take 60/6000 seconds which is 10 ms.<br/>Therefore average rotational latency is half of 10 ms, which is 5ms.<br/>Average disk access time = seek time + rotational latency<br/> 
                         = 10 ms + 5 ms<br/> 
                         = 15 ms<br/>
For 100 libraries, the average disk access time will be 15*100 ms</p>
<br/><br/>

<p><b>Q.30</b>Consider the following table of arrival time and burst time for three processes P0, P1 and P2.(GATE 2011 CS01)</b></p>
<table>
<thead>
<th>Process name</th><th>Arrival time</th><th>Burst time</th>
</thead>
<tbody>
<tr>
<th>P0</th><th>0ms</th><th>9ms</th>
</tr>
<tr>
<th>P1</th><th>1ms</th><th>4ms</th>
</tr>
<tr>
<th>P2</th><th>2ms</th><th>9ms</th>
</tr>
</tbody>
</table>
<p>The pre-emptive shortest job first scheduling algorithm is used. Scheduling is carried out only at arrival or completion of processes. What is the average waiting time for the three processes?</p>
<ol>
<li><p>5.0 ms</p></li>
<li><p>4.33 ms</p></li>
<li><p>6.33 ms</p></li>
<li><p>7.33 ms</p></li>
</ol>
<p><b>Ans:</b>(1).5.0 ms</p>
<p>Explanation:</p>
<p>Process P0 is allocated processor at 0 ms as there is no other process in ready queue.<br/>P0 is preempted after 1 ms as P1 arrives at 1 ms and burst time for P1 is less than remaining time of P0. P1 runs for 4ms.<br/>P2 arrived at 2 ms but P1 continued as burst time of P2 is longer than P1. After P1 completes, P0 is scheduled again as the remaining time for P0 is less than the burst time of P2.<br/>
P0 waits for 4 ms, P1 waits for 0 ms amd P2 waits for 11 ms.<br/>So average waiting time is (0+4+11)/3 = 5.</p>
<br/><br/>

<p><b>Q.31.</b>Consider the methods used by processes P1 and P2 for accessing their critical sections whenever needed, as given below. The initial values of shared boolean variables S1 and S2 are randomly assigned.<b>(GATE 2010 CS01)</b></p>
<p>Method Used by P1<br/>
while (S1 == S2) ;<br/>
Critica1 Section<br/>
S1 = S2;<br/>

Method Used by P2<br/>
while (S1 != S2) ;<br/>
Critica1 Section<br/>
S2 = not (S1);</p>
<p>Which one of the following statements describes the properties achieved?</p>
<ol>
<li><p>Mutual exclusion but not progress</p></li>
<li><p>Progress but not mutual exclusion</p></li>
<li><p>Neither mutual exclusion nor progress</p></li>
<li><p>Both mutual exclusion and progress</p></li>
</ol>
<p><b>Ans . </b>(1).Mutual exclusion but not progress</p>
<p>Solution:</p>
<p>Mutual exclusion  is satisfied:</br>
A way of making sure that if one process is using a shared modifiable data, the other processes will be excluded from doing the same thing. while one process executes the shared variable, all other processes desiring to do so at the same time moment should be kept waiting; when that process has finished executing the shared variable, one of the processes waiting; while that process has finished executing the shared variable, one of the processes waiting to do so should be allowed to proceed. In this fashion, each process executing the shared data (variables) excludes all others from doing so simultaneously. This is called Mutual Exclusion.<br/><br/>
Progress Requrement:<br/>  
If no process is executing in its critical section and there exist some processes that wish to enter their critical section, then the selection of the processes that will enter the critical section next cannot be postponed indefinitely.<br/><br/>
Solution:<br/>
It can be easily observed that the Mutual Exclusion requirement is satisfied by the above solution, P1 can enter critical section only if S1 is not equal to S2, and P2 can enter critical section only if S1 is equal to S2. But here Progress Requirement is not satisfied. Suppose when s1=1 and s2=0 and process p1 is not interested to enter into critical section but p2 want to enter critical section. P2 is not able to enter critical section in this as only when p1 finishes execution, then only p2 can enter (then only s1 = s2 condition be satisfied). Progress will not be satisfied when any process which is not interested to enter into the critical section will not allow other interested process to enter into the critical section.<br/>
</p>
<br/><br/>

<p><b>Q.32.</b>Which of the following statements are true? <b>(GATE 2010)</b>
<br/>
<p>I.Shortest remaining time first scheduling may cause starvation</p>
<p>II.Preemptive scheduling may cause starvation</p>
III.Round robin is better than FCFS in terms of response time</p>

<ol>
<li><p>I only</p></li>
<li><p>I and III only</p></li>
<li><p>II and III only</p></li>
<li><p>I, II and III</p></li>
</ol>
<p><b>Ans . </b>(4).I, II and III</p>
<p>Solution:</p>
<p>I) Shortest remaining time first scheduling is a preemptive version of shortest job scheduling.It may cause starvation as shorter processes may keep coming and a long CPU burst process never gets CPU.<br/>
II) Preemption may cause starvation.If priority based scheduling with preemption is used, then a low priority process may never get CPU.<br/>
III) Round Robin Scheduling improves response time as all processes get CPU after a specified time.</p>
<br/><br/>

<p><b>Q.33.</b>Consider a system with 4 types of resources R1 (3 units), R2 (2 units), R3 (3 units), R4 (2 units). A non-preemptive resource allocation policy is used. At any given instance, a request is not entertained if it cannot be completely satisfied. Three processes P1, P2, P3 request the sources as follows if executed independently. <b>(GATE 2009)</b>
</br>
<strong>Process P1: </strong>
</br>
t=0: requests 2 units of R2</br>
t=1: requests 1 unit of R3</br> 
t=3: requests 2 units of R1</br> 
t=5: releases 1 unit of R2 and 1 unit of R1.</br> 
t=7: releases 1 unit of R3</br> 
t=8: requests 2 units of R4</br> 
t=10: Finishes</br>
<strong>Process P2: </strong></br>
t=0: requests 2 units of R3</br> 
t=2: requests 1 unit of R4</br> 
t=4: requests 1 unit of R1</br> 
t=6: releases 1 unit of R3</br> 
t=8: Finishes</br>
<strong>Process P3: </strong></br>
t=0: requests 1 unit of R4</br> 
t=2: requests 2 units of R1</br> 
t=5: releases 2 units of R1</br> 
t=7: requests 1 unit of R2</br> 
t=8: requests 1 unit of R3</br> 
t=9: Finishes</br>
Which one of the following statements is TRUE if all three processes run concurrently starting at time t=0?</br></p>
<ol>
<li><p>All processes will finish without any deadlock</p></li>
<li><p> Only P1 and P2 will be in deadlock.</p></li>
<li><p>Only P1 and P3 will be in a deadlock.</p></li>
<li><p>All three processes will be in deadlock</p></li>
</ol>
<p><b>Ans . </b>(1).All processes will finish without any deadlock</p>
 <p><b>Explanation:</b></p>
<p>We can apply the following Deadlock Detection algorithm and see that there is no process waiting indefinitely for a resource.</p>
<br/><br/>

<p><b>Q.34.</b>Consider a disk system with 100 cylinders. The requests to access the cylinders occur in following sequence:
4, 34, 10, 7, 19, 73, 2, 15, 6, 20
Assuming that the head is currently at cylinder 50, what is the time taken to satisfy all requests if it takes 1ms to move from one cylinder to adjacent one and shortest seek time first policy is used?<b>(GATE 2009)</b></p>
<br/>
<ol>
<li><p>95 ms</p></li>
<li><p>119 ms</p></li>
<li><p>233 ms</p></li>
<li><p>276 ms</p></li>
</ol>
<p><b>Ans . </b>(2).119 ms</p>
<p>Explanation:</p>
<p>4, 34, 10, 7, 19, 73, 2, 15, 6, 20<br/>
Since shortest seek time first policy is used, head will first move to 34. This move will cause 16*1 ms.<br/>After 34, head will move to 20 which will cause 14*1 ms.<br/>And so on. So cylinders are accessed in following order 34, 20, 19, 15, 10, 7, 6, 4, 2, 73 and total time will be (16 + 14 + 1 + 4 + 5 + 3 + 1 + 2 + 2 + 71)*1 = 119 ms.<br/></p>
<br/><br/>

<p><b>Q.35.</b>In the following process state transition diagram for a uniprocessor system, assume that there are always some processes in the ready state: Now consider the following statements:<b>(GATE 2009)</b></p>
<br/>
<img src="images/solution10.png">
<p>I. If a process makes a transition D, it would result in 
   another process making transition A immediately.</p>
<p>II. A process P2 in blocked state can make transition E 
    while another process P1 is in running state.</p>
<p>III. The OS uses preemptive scheduling.</p>
<p>IV. The OS uses non-preemptive scheduling.</p>
<p>Which of the above statements are TRUE?</p>
<ol>
<li><p>I and II</p></li>
<li><p>I and III</p></li>
<li><p>II and III</p></li>
<li><p>II and IV</p></li>
</ol>
<p><b>Ans.</b>(3).II and III</p>
<p>Explanation:</p>
<p> I is false. If a process makes a transition D, it would result in another process making transition B, not A.<br/>
II is true. <br/>A process can move to ready state when I/O completes irrespective of other process being in running state or not.<br/>
III is true because there is a transition from running to ready state.<br/>
IV is false as the OS uses preemptive scheduling.</p>
<br/><br/>

<p><b>Q.36.</b>The enter_CS() and leave_CS() functions to implement critical section of a process are realized using test-and-set instruction as follows:<b>(GATE 2009)</b></p>
<p>void enter_CS(X)<br/>
{<br/>
    while test-and-set(X) ;<br/>
}<br/>
void leave_CS(X)<br/>
{<br/>
   X = 0;<br/>
}<br/></p>
<p>In the above solution, X is a memory location associated with the CS and is initialized to 0. Now consider the following statements:</p>
<p>I. The above solution to CS problem is deadlock-free</p>
<p>II. The solution is starvation free.</p>
<p>III. The processes enter CS in FIFO order.</p>
<p>IV More than one process can enter CS at the same time.</p>
<p> Which of the above statements is TRUE?</p>
<ol>
<li><p>I only</p></li>
<li><p>I and II</p></li>
<li><p>II and III</p></li>
<li><p>IV only</p></li>
</ol>
<p><b>Ans . </b>(1).I only</p>
<p>Explanation:</p>
<p>The above solution is a simple test-and-set solution that makes sure that deadlock doesn’t occur, but it doesn’t use any queue to avoid starvation or to have FIFO order.</p>
<br/><br/>

<p><b>Q.37.</b>The P and V operations on counting semaphores, where s is a counting semaphore, are defined as follows:<b>(GATE 2008)</b></p>
<p>P(s) : s =  s - 1;<br/>
  if (s  < 0) then wait;<br/>
V(s) : s = s + 1;<br/>
  if (s <= 0) then wakeup a process waiting on s;<br/></p>
<p>Assume that Pb and Vb the wait and signal operations on binary semaphores are provided. Two binary semaphores Xb and Yb are used to implement the semaphore operations P(s) and V(s) as follows:<br/></p>
<p>P(s) : Pb(Xb);<br/>
  s = s - 1;<br/>
  if (s < 0) {<br/>
   Vb(Xb) ;<br/>
   Pb(Yb) ;<br/>
  }<br/>
  else Vb(Xb);<br/> </p>
<p>V(s) : Pb(Xb) ;<br/>
  s = s + 1;<br/>
  if (s <= 0) Vb(Yb) ;<br/>
  Vb(Xb) ;<br/></p>
<p>The initial values of Xb and Yb are respectively</p>
<ol>
<li><p>0 and 0</p></li>
<li><p>0 and 1</p></li>
<li><p>1 and 0</p></li>
<li><p>1 and 1</p></li>
</ol>
<p><b>Ans.</b>(3).1 and 0</p>
<p>Explanation:</p>
<p>Suppose Xb = 0, then because of P(s): Pb(Xb) operation, Xb will be -1 and processs will get blocked as it will enter into waiting section.</p>
<p>So, Xb will be one.</p>
<p>Suppose s=2(means 2 process are accessing shared resource), taking Xb as 1,</p>
<p>first P(s): Pb(Xb) operation will make Xb as zero. s will be 1 and Then Vb(Xb) operation will be executed which will increase the count of Xb as one. Then same process will be repeated making Xb as one and s as zero.</p>
<p>Now suppose one more process comes, then Xb will be 1 but s will be -1 which will make this process go into loop (s <0) and will result into calling Vb(Xb) and Pb(Yb) operations. Vb(Xb) will result into Xb as 2 and Pb(Yb) will result into decrementing the value of Yb.</p>
<p>case 1: if Yb has value as 0, it will be -1 and it will go into waiting and will be blocked.total 2 process will access shared resource (according to counting semaphore, max 3 process can access shared resource) and value of s is -1 means only 1 process will be waiting for resources and just now, one process got blocked. So it is still true.</p>
<p>case 2: if Yb has value as 1, it will be 0. Total 3 process will access shared resource (according to counting semaphore, max 3 process can access shared resource) and value of s is -1 means only 1 process will be waiting for resources and but there is no process waiting for resources.So it is false.</p>
<br/><br/>

<p><b>Q.38.</b>Which of the following is NOT true of deadlock prevention and deadlock avoidance schemes?<b>(GATE 2008)</b></p>
<ol>
<li><p>In deadlock prevention, the request for resources is always granted if the resulting state is safe</p></li>
<li><p>In deadlock avoidance, the request for resources is always granted if the result state is safe</p></li>
<li><p>Deadlock avoidance is less restrictive than deadlock prevention</p></li>
<li><p>Deadlock avoidance requires knowledge of resource requirements a priority</p></li>
</ol>
<p><b>Ans.</b>(1).In deadlock prevention, the request for resources is always granted if the resulting state is safe</p>
<p>Explanation:</p>
<p>Deadlock Prevention: Deadlocks can be prevented by preventing at least one of the four required conditions:</p>
<p>1. Mutual Exclusion – not required for sharable resources; must hold for non-sharable resources.</p>
<p>2. Hold and Wait – must guarantee that whenever a process requests a resource, it does not hold any other resources. Require process to request and be allocated all its sources before it begins execution, or allow process to request resources only when the process has none. Low resource utilization; starvation possible. Restrain the ways request can be made.</p>
<p>3. No Pre-emption – If a process that is holding some resources requests another resource that cannot be immediately allocated to it, and then all resources currently being held are released. Pre-empted resources are added to the list of resources for which the process is waiting. Process will be restarted only when it can regain its old resources, as well as the new ones that it is requesting.</p>
<p>4. Circular Wait – impose a total ordering of all resource types, and require that each process requests resources in an increasing order of enumeration.</p>
<p>Deadlock Avoidance:</p>
<p>When a scheduler sees that starting a process or granting resource requests may lead to future deadlocks, then that process is just not started or the request is not granted. The deadlock-avoidance algorithm dynamically examines the resource-allocation state to ensure that there can never be a circular-wait condition. Resource-allocation state is defined by the number of available and allocated resources, and the maximum demands of the processes.</p>
<p>Choice of the question:</p>
<p>(A) In deadlock prevention, the request for resources is always granted if the resulting state is safe. false, Deadlock prevention scheme handles deadlock by making sure that one of the four necessary conditions don’t occur. In deadlock prevention, the request for a resource may not be granted even if the resulting state is safe.</p>
<p>(B) In deadlock avoidance, the request for resources is always granted if the result state is safe. true, As in Deadlock avoidance, if resultant state is safe than request for resource is granted as being in a safe state, it can hold other resources now.</p>
<p>(C) Deadlock avoidance is less restrictive than deadlock prevention. true, As in Deadlock prevention, request for a resource may not be granted even if the resulting state is safe. but in deadlock avoidance, request for a resource is granted if the resulting state is safe.</p>
<p>(D) Deadlock avoidance requires knowledge of resource requirements a priority true, deadlock avoidance checks any chance of deadlock means even if the system is in safe state, it checks that after allocating requested resource, the system is not in deadlocked state. So deadlock avoidance requires knowledge of resource requirements a priority.</p>
<br/><br/>

<p><b>Q.39.</b>A process executes the following code<b>(GATE 2008)</b></p>
<p>for (i = 0; i < n; i++) fork();</p>
<p>The total number of child processes created is</p>
<ol>
<li><p>n</p></li>
<li><p>2^n – 1</p></li>
<li><p>2^n</p></li>
<li><p>2^(n+1) – 1;</p></li>
</ol>
<p><b>Ans . </b>(2).2^n – 1</p>
<p>Explanation:</p>
<p>F0       // There will be 1 child process created by first fork</p>
<p>      /     \</p>
<p>F1      F1    // There will be 2 child processes created by second fork</p>
<p>/  \    /  \</p>
<p>F2   F2  F2   F2  // There will be 4 child processes created by third fork</p>
<p>/ \   / \ / \  / \</p>
<p> ...............   // and so on</p>
<p>If we sum all levels of above tree for i = 0 to n-1, we get 2^n – 1. So there will be 2^n – 1 child processes.</p>
<br/><br/>

<p><b>Q.40.</b>Consider the following statements about user level threads and kernel level threads. Which one of the following statement is FALSE?<b>(GATE 2007)</b></p>
<ol>
<li><p>Context switch time is longer for kernel level threads than for user level threads.</p></li>
<li><p> User level threads do not need any hardware support.</p></li>
<li><p>Related kernel level threads can be scheduled on different processors in a multi-processor system.</p></li>
<li><p>Blocking one kernel level thread blocks all related threads.</p></li>
</ol>
<p><b>Ans . </b>(4).Blocking one kernel level thread blocks all related threads.</p>
<p>Explanation:</p>
<p>Kernel level threads are managed by the OS, therefore, thread operations are implemented in the kernel code. Kernel level threads can also utilize multiprocessor systems by splitting threads on different processors. If one thread blocks it does not cause the entire process to block. Kernel level threads have disadvantages as well. They are slower than user level threads due to the management overhead. Kernel level context switch involves more steps than just saving some registers. Finally, they are not portable because the implementation is operating system dependent.</p>
<p>option (A): Context switch time is longer for kernel level threads than for user level threads. True, As User level threads are managed by user and Kernel level threads are managed by OS. There are many overheads involved in Kernel level thread management, which are not present in User level thread management. So context switch time is longer for kernel level threads than for user level threads.</p>
<p>Option (B): User level threads do not need any hardware support True, as User level threads are managed by user and implemented by Libraries, User level threads do not need any hardware support.</p>
<p>Option (C): Related kernel level threads can be scheduled on different processors in a multi- processor system. This is true.</p>
<p>Option (D): Blocking one kernel level thread blocks all related threads. false, since kernel level threads are managed by operating system, if one thread blocks, it does not cause all threads or entire process to block.</p>
<br/><br/>

<p><b>Q.41.</b>An operating system uses Shortest Remaining Time first (SRT) process scheduling algorithm. Consider the arrival times and execution times for the following processes:<b>(GATE 2007)</b></p>
<table>
<thead>
<th>Process </th><th>Execution time</th><th>Arrival time</th>
</thead>
<tbody>
<tr>
<th>P1</th><th>20</th><th>0</th>
</tr>
<tr>
<th>P2</th><th>25</th><th>15</th>
</tr>
<tr>
<th>P3</th><th>10</th><th>30</th>
</tr>
<tr>
<th>P4</th><th>15</th><th>45</th>
</tr>
</tbody>
</table>
<p>What is the total waiting time for process P2?</p>
<ol>
<li><p>5</p></li>
<li><p>15</p></li>
<li><p>40</p></li>
<li><p>55</p></li>
</ol>
<p><b>Ans . </b>(2).15</p>
<p>Explanation:</p>
<p>Shortest remaining time, also known as shortest remaining time first (SRTF), is a scheduling method that is a pre-emptive version of shortest job next scheduling. In this scheduling algorithm, the process with the smallest amount of time remaining until completion is selected to execute. Since the currently executing process is the one with the shortest amount of time remaining by definition, and since that time should only reduce as execution progresses, processes will always run until they complete or a new process is added that requires a smaller amount of time.</p>
<p>The Gantt chart of execution of processes:</p>
<img src="images/solution11.png">
<p>At time 0, P1 is the only process, P1 runs for 15 time units.</p>
<p>At time 15, P2 arrives, but P1 has the shortest remaining time. So P1 continues for 5 more time units.</p>
<p>At time 20, P2 is the only process. So it runs for 10 time units.</p>
<p>at time 30, P3 is the shortest remaining time process. So it runs for 10 time units.</p>
<p>at time 40, P2 runs as it is the only process. P2 runs for 5 time units.</p>
<p>At time 45, P3 arrives, but P2 has the shortest remaining time. So P2 continues for 10 more time units. P2 completes its execution at time 55.</p>
<img src="images/solution12.png">
<p>As we know, turn around time is total time between submission of the process and its completion. Waiting time is the time The amount of time that is taken by a process in ready queue and waiting time is the difference between Turn around time and burst time.</p>
<p>Total turnaround time for P2 = Completion time – Arrival time = 55 – 15 = 40</p>
<p>Total Waiting Time for P2= turn around time – Burst time = 40 – 25 = 15</p>
<br/><br/>

<p><b>Q.42.</b>A single processor system has three resource types X, Y and Z, which are shared by three processes. There are 5 units of each resource type. Consider the following scenario, where the column alloc denotes the number of units of each resource type allocated to each process, and the column request denotes the number of units of each resource type requested by a process in order to complete execution. Which of these processes will finish LAST?<b>(GATE 2007)</b></p>
<table>
<thead>
<th>Process </th><th>alloc</th><th>request</th>
</thead>
<tbody>
<tr>
<th>&nbsp</th><th>X Y Z</th><th>X Y Z</th>
</tr>
<tr>
<th>P0</th><th>1 2 1</th><th>1 0 3</th>
</tr>
<tr>
<th>P1</th><th>2 0 1</th><th>0 1 2</th>
</tr>
<tr>
<th>P2</th><th>2 2 1</th><th>1 2 0</th>
</tr>
</tbody>
</table>
<ol>
<li><p>P0</p></li>
<li><p>P1</p></li>
<li><p>P2</p></li>
<li><p>None of the above, since the system is in a deadlock</p></li>
</ol>
<p><b>Ans . </b>(3).P2</p>
<p>Explanation:</p>
<p>A single processor system has three resource types X, Y and Z, which are shared by three processes. There are 5 units of each resource type.</p>
<p>So, the resource instances which are left being unallocated = { unallocated resources= total resources-allocated resources }</p>
<img src="images/solution13.png">
<p>now, from the request table, you can say that only request of P1 can be satisfied. So P1 can finish its execution first. Once P1 is done, it releases 2, 0 and 1 units of X, Y and Z
respectively which were allocated to P1.So, Now unallocated resource instance are = + =</p>
<p>Now Among P0 and P2, needs of P0 can only be satisfied. So P0 finishes its execution. Once P2 is done, It releases 2,2,and 1 units of X,Y and Z respectively which were allocated to P2.SO, Now unallocated resource instance are= + = . Finally, P2 finishes its execution. So, P2 is the process which finishes in end.</p>
<p>Option (C) is the correct answer.</p>
<br/><br/>

<p><b>Q.43.</b>Two processes, P1 and P2, need to access a critical section of code. Consider the following synchronization construct used by the processes:Here, wants1 and wants2 are shared variables, which are initialized to false. Which one of the following statements is TRUE about the above construct?<b>(GATE 2007)</b></p>
<p>/* P1 */<br/>
while (true) {<br/>
  wants1 = true;<br/>
  while (wants2 == true);<br/>
  /* Critical Section */<br/>
  wants1=false;<br/>
}<br/>
/* Remainder section */<br/></p>
<p>/* P2 */<br/>
while (true) {<br/>
  wants2 = true;<br/>
  while (wants1==true);<br/>
  /* Critical Section */<br/>
  wants2 = false;<br/>
}<br/>
/* Remainder section */<br/></p>
<ol>
<li><p>It does not ensure mutual exclusion.</p></li>
<li><p>It does not ensure bounded waiting.</p></li>
<li><p>It requires that processes enter the critical section in strict alternation.</p></li>
<li><p>It does not prevent deadlocks, but ensures mutual exclusion.</p></li>
</ol>
<p><b>Ans . </b>(4).It does not prevent deadlocks, but ensures mutual exclusion.</p>
<p>Explanation:</p>
<p>Bounded waiting :There exists a bound, or limit, on the number of times other processes are allowed to enter their critical sections after a process has made request to enter its critical section and before that request is granted.</p>
<p>mutual exclusion prevents simultaneous access to a shared resource. This concept is used in concurrent programming with a critical section, a piece of code in which processes or threads access a shared resource.</p>
<p>Solution:</p>
<p>Two processes, P1 and P2, need to access a critical section of code. Here, wants1 and wants2 are shared variables, which are initialized to false.</p>
<p>Now, when both wants1 and wants2 become true, both process p1 and p2 enter in while loop and waiting for each other to finish. This while loop run indefinitely which leads to deadlock.</p>
<p>Now, Assume P1 is in critical section (it means wants1=true, wants2 can be anything, true or false). So this ensures that p2 won’t enter in critical section and vice versa. This satisfies the property of mutual exclusion.</p>
<p>Here bounded waiting condition is also satisfied as there is a bound on the number of process which gets access to critical section after a process request access to it.</p>
<br/><br/>

<p><b>Q.44.</b>Consider three CPU-intensive processes, which require 10, 20 and 30 time units and arrive at times 0, 2 and 6, respectively. How many context switches are needed if the operating system implements a shortest remaining time first scheduling algorithm? Do not count the context switches at time zero and at the end.<b>(GATE 2006)</b></p>
<ol>
<li><p>1</p></li>
<li><p>2</p></li>
<li><p>3</p></li>
<li><p>4</p></li>
</ol>
<p><b>Ans . </b>(2).2</p>
<p>Explanation:</p>
<p>Shortest remaining time, also known as shortest remaining time first (SRTF), is a scheduling method that is a pre-emptive version of shortest job next scheduling. In this scheduling algorithm, the process with the smallest amount of time remaining until completion is selected to execute. Since the currently executing process is the one with the shortest amount of time remaining by definition, and since that time should only reduce as execution progresses, processes will always run until they complete or a new process is added that requires a smaller amount of time.</p>
<p>Solution:</p>
<p>Let three process be P0, P1 and P2 with arrival times 0, 2 and 6 respectively and CPU burst times 10, 20 and 30 respectively. At time 0, P0 is the only available process so it runs. At time 2, P1 arrives, but P0 has the shortest remaining time, so it continues. At time 6, P2 also arrives, but P0 still has the shortest remaining time, so it continues. At time 10, P1 is scheduled as it is the shortest remaining time process. At time 30, P2 is scheduled. Only two context switches are needed. P0 to P1 and P1 to P2.</p>
<br/><br/>

<p><b>Q.45.</b>The atomic fetch-and-set x, y instruction unconditionally sets the memory location x to 1 and fetches the old value of x n y without allowing any intervening access to the memory location x. consider the following implementation of P and V functions on a binary semaphore S.<b>(GATE 2006)</b></p>
<p>void P (binary_semaphore *s)<br/>
{<br/>
    unsigned y;<br/>
    unsigned *x = &(s->value);<br/>
    do<br/>
    {<br/>
        fetch-and-set x, y;<br/>
    }<br/>
    while (y);<br/>
}<br/>
void V (binary_semaphore *s)<br/>
{<br/>
    S->value = 0;<br/>
}</p>
<p>Which one of the following is true?</p>
<ol>
<li><p>The implementation may not work if context switching is disabled in P</p></li>
<li><p>Instead of using fetch-and –set, a pair of normal load/store can be used</p></li>
<li><p>The implementation of V is wrong</p></li>
<li><p>The code does not implement a binary semaphore</p></li>
</ol>
<p><b>Ans . </b>(1).The implementation may not work if context switching is disabled in P</p>
<p>Explanation:</p>
<p>Let us talk about the operation P(). It stores the value of s in x, then it fetches the old value of x, stores it in y and sets x as 1. The while loop of a process will continue forever if some other process doesn’t execute V() and sets the value of s as 0. If context switching is disabled in P, the while loop will run forever as no other process will be able to execute V().</p>
<br/><br/>

<p><b>Q.46.</b>Consider three processes (process id 0, 1, 2 respectively) with compute time bursts 2, 4 and 8 time units. All processes arrive at time zero. Consider the longest remaining time first (LRTF) scheduling algorithm. In LRTF ties are broken by giving priority to the process with the lowest process id. The average turn around time is:<b>(GATE 2006)</b></p>
<ol>
<li><p>13 units</p></li>
<li><p>14 units</p></li>
<li><p>15 units</p></li>
<li><p>16 units</p></li>
</ol>
<p><b>Ans.</b>(1).13 units</p>
<p>Explanation:</p>
<p><strong>Background Explanation:</strong></p>
<p>Turn around time of a process is total time between submission of the process and its completion.LRTF(Longest Remaining Time First), means the process which has remaining time largest, will run first and in case of same remaining time, lowest process with will be given priority to run.</p>
<p>Solution:</p>
<p>Let the processes be p0, p1 and p2. These processes will be executed in following order.</p>
<p>Gantt chart is as follows:</p>
<p>p2&nbspp1&nbspp2&nbsp&nbspp1&nbspp2&nbspp0&nbspp1&nbspp2&nbspp0&nbspp1&nbspp2<br/>
0&nbsp&nbsp4&nbsp&nbsp5&nbsp&nbsp6&nbsp&nbsp7&nbsp&nbsp8&nbsp&nbsp9&nbsp&nbsp10&nbsp&nbsp11&nbsp&nbsp12&nbsp&nbsp13&nbsp&nbsp14</p>
<p>First 4 sec, p2 will run, then remaining time p2=4, p1=4, p0=2. Now P1 will get chance to run for 1 sec, then remaining time. p2=4,p1=3,p0=2. Now p2 will get chance to run for 1 sec, then remaining time. p2=3,p1=3,p0=2.</p>
<p>By doing this way, you will get above gantt chart.</p>
<p>Scheduling table:</p>
<img src="images/solution14.png">
<p>AT=Arrival Time, BT=Burst Time, CT=Completion Time, TAT=Turn Around Time As we know, turn around time is total time between submission of the process and its completion. i.e turn around time=completion time-arrival time. i.e. TAT=CT-AT Turn around time of p0 = 12 (12-0) Turn around time of p1 = 13 (13-0) Turn around time of p2 = 14 (14-0)</p>
<p>Average turn around time is (12+13+14)/3 = 13.</p>
<p>Option (A) is the correct answer.</p>
<br/><br/>

<p><b>Q.47.</b>Consider three processes, all arriving at time zero, with total execution time of 10, 20 and 30 units, respectively. Each process spends the first 20% of execution time doing I/O, the next 70% of time doing computation, and the last 10% of time doing I/O again. The operating system uses a shortest remaining compute time first scheduling algorithm and schedules a new process either when the running process gets blocked on I/O or when the running process finishes its compute burst. Assume that all I/O operations can be overlapped as much as possible. For what percentage of time does the CPU remain idle?<b>(GATE 2006)</b></p>
<ol>
<li><p>0%</p></li>
<li><p>10.6%</p></li>
<li><p>30.0%</p></li>
<li><p>89.4%</p></li>
</ol>
<p><b>Ans.</b>(2).10.6%</p>
<p>Explanation:</p>
<p>Shortest remaining time ( SRT ) scheduling algorithm selects the process for execution which has the smallest amount of time remaining until completion.</p>
<p>Let three processes be p0, p1 and p2. Their execution time is 10, 20 and 30 respectively.</p>
<p>p0 spends first 2 time units in I/O, 7 units of CPU time and finally 1 unit in I/O.</p>
<p>p1 spends first 4 units in I/O, 14 units of CPU time and finally 2 units in I/O.</p>
<p>p2 spends first 6 units in I/O, 21 units of CPU time and finally 3 units in I/O.</p>
<img src="images/solution15.png">
<p>AT- Arrival Time, IO-input/output, BT-Burst Time</p>
<p>first process p0 will spend 2 units in IO, next 7 units in BT, then process p1 will spend 14 units in BT (as its 4 units of IO has been spent already when previous process was running) and ten process p2 will spend 21 units in BT (as its 6 units of IO has been spent already when previous processes were running) and atlast 3 units in IO (process p0,p1,p2’s last IO included.)</p>
<p>idle&nbsp&nbspp0&nbsp&nbspp1&nbsp&nbspp2&nbsp&nbspidle</br>
0&nbsp&nbsp2&nbsp&nbsp9&nbsp&nbsp23&nbsp&nbsp44&nbsp&nbsp47</p>
<p>Total time spent = 47</p>
<p>Idle time = 2 + 3 = 5</p>
<p>Percentage of idle time = (5/47)*100 = 10.6 %</p>
<br/><br/>

<p><b>Q.48.</b>Consider the following snapshot of a system running n processes. Process i is holding Xi instances of a resource R, 1 <= i <= n. currently, all instances of R are occupied. Further, for all i, process i has placed a request for an additional Yi instances while holding the Xi instances it already has. There are exactly two processes p and q such that Yp = Yq = 0. Which one of the following can serve as a necessary condition to guarantee that the system is not approaching a deadlock?<b>(GATE 2006)</b></p>
<ol>
<li><p>min (Xp, Xq) < max (Yk) where k != p and k != q</p></li>
<li><p>Xp + Xq >= min (Yk) where k != p and k != q</p></li>
<li><p>max (Xp, Xq) > 1</p></li>
<li><p>min (Xp, Xq) > 1</p></li>
</ol>
<p><b>Ans. </b>(2).Xp + Xq >= min (Yk) where k != p and k != q</p>
<p>Explanation:</p>
<p>Deadlock refers to a specific condition when two or more processes are each waiting for another to release a resource, or more than two processes are waiting for resources.</p>
<p>Solution:</p>
<p>Necessary condition to guarantee no deadlock which means without satisfying this condition, no deadlock is possible. Both the process p and q have no additional requirement; they both can be finished releasing Xp + Xq resources without asking for any additional resource.</p>
<p>Using this, we can finish one more process only if condition B is satisfied. If the resources released by p and q are sufficient for another process waiting for Yk resources, then system is not approaching deadlock.</p>
<p>i.e Xp+Xq > min (Yk) where k != p and k != q</p>
<p>Note: Option B just ensured that the system can proceed from the current state. It does not guarantee that there won’t be a deadlock before all processes are finished.</p>
<br/><br/>

<p><b>Q.49.</b>Suppose n processes, P1, …. Pn share m identical resource units, which can be reserved and released one at a time. The maximum resource requirement of process Pi is Si, where Si > 0. Which one of the following is a sufficient condition for ensuring that deadlock does not occur? <b>(GATE 2005)</b></p>
<img src="images/solution16.png">
<ol>
<li><p>A</p></li>
<li><p>B</p></li>
<li><p>C</p></li>
<li><p>D</p></li>
</ol>
<p><b>Ans. </b>(3).C</p>
<p>Explanation:</p>
<p>In the extreme condition, all processes acquire Si-1 resources and need 1 more resource. So following condition must be true to make sure that deadlock never occurs.</p>
<p><img src="images/solution17.png"> < m The above expression can be written as following. <img src="images/solution18.png"> < (m + n) </p>
<br/><br/>

<p><b>Q.50.</b>Consider the following code fragment:<b>(GATE 2005)</b></p>
<p> if (fork() == 0)<br/>
  {<br/> a = a + 5;<br/> printf(“%d,%d\n”, a, &a);<br/> }<br/>
  else {<br/> a = a –5;<br/> printf(“%d, %d\n”, a, &a);<br/> } </p>
<p>Let u, v be the values printed by the parent process, and x, y be the values printed by the child process.</p>
<p>Which one of the following is TRUE?</p>
<ol>
<li><p>u = x + 10 and v = y</p></li>
<li><p>u = x + 10 and v != y</p></li>
<li><p>u + 10 = x and v = y</p></li>
<li><p>u + 10 = x and v != y</p></li>
</ol>
<p><b>Ans.</b>(3).u + 10 = x and v = y</p>
<p>Explanation:</p>
<p>When a fork() system call is issued, a copy of all the pages corresponding to the parent process is created, loaded into a separate memory location by the OS for the child process. But this is not needed in certain cases. When the child is needed just to execute a command for the parent process, there is no need for copying the parent process’ pages, since exec replaces the address space of the process which invoked it with the command to be executed. In such cases, a technique called copy-on-write (COW) is used.</p>
<p>With this technique, when a fork occurs, the parent process’s pages are not copied for the child process. Instead, the pages are shared between the child and the parent process. Whenever a process (parent or child) modifies a page, a separate copy of that particular page alone is made for that process (parent or child) which performed the modification. This process will then use the newly copied page rather than the shared one in all future references.</p>
<p>fork() returns 0 in child process and process ID of child process in parent process.</p>
<p>In Child (x), a = a + 5</p>
<p>In Parent (u), a = a – 5;</p>
<p>Child process will execute the if part and parent process will execute the else part. Assume that the initial value of a = 6. Then the value of a printed by the child process will be 11, and the value of a printed by the parent process in 1. Therefore u+10=x Now the second part. The answer is v = y.</p>
<p>We know that, the fork operation creates a separate address space for the child. But the child process has an exact copy of all the memory segments of the parent process. Hence the virtual addresses and the mapping (initially) will be the same for both parent process as well as child process.</p>
<p>PS: the virtual address is same but virtual addresses exist in different processes’ virtual address space and when we print &a, it’s actually printing the virtual address. Hence the answer is v = y.</p>
<br/><br/>

<p><b>Q.51.</b>Consider an operating system capable of loading and executing a single sequential user process at a time. The disk head scheduling algorithm used is First Come First Served (FCFS). If FCFS is replaced by Shortest Seek Time First (SSTF), claimed by the vendor to give 50% better benchmark results, what is the expected improvement in the I/O performance of user programs?<b>(GATE 2004)</b></p>
<ol>
<li><p>50%</p></li>
<li><p>40%</p></li>
<li><p>25%</p></li>
<li><p>0%</p></li>
</ol>
<p><b>Ans.</b>(4).0%</p>
<p>Explanation:</p>
<p>Since Operating System can execute a single sequential user process at a time, the disk is accessed in FCFS manner always. The OS never has a choice to pick an IO from multiple IOs as there is always one IO at a time</p>
<br/><br/>

<p><b>Q.52.</b>Consider the following set of processes, with the arrival times and the CPU-burst times given in milliseconds<b>(GATE 2004)</b></p>
<p><table border="1">
<thead>
<tr>
<th>Process</th><th>Arrival Time</th><th>Burst time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td><td>0</td><td>5</td>
</tr>
<tr>
<td>P2</td><td>1</td><td>3</td>
</tr>
<tr>
<td>P3</td><td>2</td><td>3</td>
</tr>
<tr>
<td>P4</td><td>4</td><td>1</td>
</tr>
</tbody>
</table>
</p>
<p>What is the average turnaround time for these processes with the preemptive shortest remaining processing time first (SRPT) algorithm ?</p>
<ol>
<li><p>5.50</p></li>
<li><p>5.75</p></li>
<li><p>6.00</p></li>
<li><p>6.25</p></li>
</ol>
<p><b>Ans.</b>(1).5.50</p>
<p>Explanation:</p>
<p>The following is Gantt Chart of execution</p>
<p>P1&nbsp&nbspP2&nbsp&nbspP4&nbsp&nbspP3&nbsp&nbspP1</br>
1&nbsp&nbsp&nbsp&nbsp4&nbsp&nbsp&nbsp&nbsp5&nbsp&nbsp&nbsp&nbsp8&nbsp&nbsp&nbsp&nbsp12</p>
<p>Turn Around Time = Completion Time – Arrival Time</p>
<p>Avg Turn Around Time  =  (12 + 3 + 6+  1)/4 = 5.50</p>
<br/><br/>

<p><b>Q.53.</b>Consider two processes P1 and P2 accessing the shared variables X and Y protected by two binary semaphores SX and SY respectively, both initialized to 1. P and V denote the usual semaphone operators, where P decrements the semaphore value, and V increments the semaphore value. The pseudo-code of P1 and P2 is as follows :<b>(GATE 2004)</b></p>
<p>P1 :</p>
<p> While true do {<br/>
   L1 : ................<br/>
   L2 : ................<br/>
   X = X + 1;<br/>
   Y = Y - 1;<br/>
   V(SX);<br/>
   V(SY); <br/>            
 }</p>
<p>P2 :</p>
<p>While true do {<br/> 
   L3 : ................ <br/>   
   L4 : ................<br/> 
   Y = Y + 1;<br/> 
   X = Y - 1;<br/> 
   V(SY);<br/> 
   V(SX);<br/>             
}</p>
<p>In order to avoid deadlock, the correct operators at L1, L2, L3 and L4 are respectively</p>
<ol>
<li><p>P(SY), P(SX); P(SX), P(SY)</p></li>
<li><p>P(SX), P(SY); P(SY), P(SX)</p></li>
<li><p>P(SX), P(SX); P(SY), P(SY)</p></li>
<li><p>P(SX), P(SY); P(SX), P(SY)</p></li>
</ol>
<p><b>Ans.</b>(4). P(SX), P(SY); P(SX), P(SY)</p>
<p>Explanation:</p>
<p>Option A: In line L1 ( p(Sy) ) i.e. process p1 wants lock on Sy that is 
held by process p2 and line L3 (p(Sx)) p2 wants lock on Sx which held by p1. 
So here circular and wait condition exist means deadlock.</p>
<p>Option B : In line L1 ( p(Sx) ) i.e. process p1 wants lock on Sx that is held 
by process p2 and line L3 (p(Sy)) p2 wants lock on Sx which held by p1. So here 
circular and wait condition exist means deadlock.</p>
<p>Option C: In line L1 ( p(Sx) ) i.e. process p1 wants lock on Sx and line L3 (p(Sy)) 
p2 wants lock on Sx . But Sx and Sy can’t be released by its processes p1 and p2.</p>
<br/><br/>

<p><b>Q.54.</b>A uni-processor computer system only has two processes, both of which alternate 10ms CPU bursts with 90ms I/O bursts. Both the processes were created at nearly the same time. The I/O of both processes can proceed in parallel. Which of the following scheduling strategies will result in the least CPU utilization (over a long period of time) for this system ?<b>(GATE 2003)</b></p>
<ol>
<li><p>First come first served scheduling</p></li>
<li><p>Shortest remaining time first scheduling</p></li>
<li><p>Static priority scheduling with different priorities for the two processes</p></li>
<li><p>Round robin scheduling with a time quantum of 5 ms</p></li>
</ol>
<p><b>Ans.</b>(4).Round robin scheduling with a time quantum of 5 ms</p>
<p>Explanation:</p>
<p>When Round Robin scheduling is used:</p>
<p>We are given that the time slice is 5ms. Consider process P and Q.
Say P utilizes 5ms of CPU and then Q utilizes 5ms of CPU. Hence after 15ms P starts with I/O And after 20ms Q also starts with I/O. Since I/O can be done in parallel, P finishes I\O at 105th ms (15 + 90) and Q finishes its I\O at 110th ms (20 + 90). Therefore we can see that CPU remains idle from 20th to 105th ms.</br>
That is when Round Robin scheduling is used,</br>
Idle time of CPU = 85ms</br>
CPU Utilization = 20/105 = 19.05%</p>
<p>When First Come First Served scheduling scheduling or Shortest Remaining Time First is used:</p>
<p>Say P utilizes 10ms of CPU and then starts its I/O. At 11th ms Q starts processing. Q utilizes 10ms of CPU.<br/>
P completes its I/O at 100ms (10 + 90)<br/>
Q completes its I/O at 110ms (20 + 90)<br/>
At 101th ms P again utilizes CPU. Hence,<br/>
Idle time of CPU = 80ms<br/>
CPU Utilization = 20/100 = 20%</p>
<p>Since only two processes are involved and I\O time is much more than CPU time, “Static priority scheduling with different priorities” for the two processes reduces to FCFS or Shortest remaining time first.</p>
<p>Therefore, Round robin will result in least CPU utilization.</p>
<br/><br/>

<p><b>Q.55.</b>Suppose we want to synchronize two concurrent processes P and Q using binary semaphores S and T. The code for the processes P and Q is shown below.<b>(GATE 2003)</b></p>
<p>Process P:<br/>
while (1) {<br/>
W:<br/>
   print '0';<br/>
   print '0';<br/>
X:<br/>
}</p>
<p>Process Q:<br/>
while (1) {<br/>
Y:<br/>
   print '1';<br/>
   print '1';<br/>
Z:<br/>
}</p>
<p>Synchronization statements can be inserted only at points W, X, Y and Z.</p>
<p>Which of the following will always lead to an output staring with ‘001100110011’ ?</p>
<ol>
<li><p>P(S) at W, V(S) at X, P(T) at Y, V(T) at Z, S and T initially 1</p></li>
<li><p>P(S) at W, V(T) at X, P(T) at Y, V(S) at Z, S initially 1, and T initially 0</p></li>
<li><p>P(S) at W, V(T) at X, P(T) at Y, V(S) at Z, S and T initially 1</p></li>
<li><p>P(S) at W, V(S) at X, P(T) at Y, V(T) at Z, S initially 1, and T initially 0</p></li>
</ol>
<p><b>Ans.</b>(2).P(S) at W, V(T) at X, P(T) at Y, V(S) at Z, S initially 1, and T initially 0</p>
<p>Explanation:</p>
<p>P(S) means wait on semaphore ‘S’ and V(S) means signal on semaphore ‘S’.</p>
<p>Wait(S)<br/>
{<br/>
    while (i <= 0)<br/> 
    --S;<br/>
}<br/>
 
Signal(S)<br/>
{<br/>
    S++;<br/>
}</p>
<p>Initially, we assume S = 1 and T = 0 to support mutual exclusion in process P and Q.</p>
<p>Since S = 1, only process P will be executed and wait(S) will decrement the value of S. </p>
<p>Therefore, S = 0.</p>
<p>At the same instant, in process Q, value of T = 0. Therefore, in process Q, control will be stuck in while loop till the time process P prints 00 and increments the value of T by calling the function V(T).</p>
<p>While the control is in process Q, semaphore S = 0 and process P would be stuck in while loop and would not execute till the time process Q prints 11 and makes the value of S = 1 by calling the function V(S).</p>
<p>This whole process will repeat to give the output 00 11 00 11 … .</p>
<p>Thus, B is the correct choice.</p>
<br/><br/>

<p><b>Q.56.</b>Suppose we want to synchronize two concurrent processes P and Q using binary semaphores S and T. The code for the processes P and Q is shown below.<b>(GATE 2003)</b></p>
<p>Process P:<br/>
while (1) {<br/>
W:<br/>
   print '0';<br/>
   print '0';<br/>
X:<br/>
}</p>
<p>Process Q:<br/>
while (1) {<br/>
Y:<br/>
   print '1';<br/>
   print '1';<br/>
Z:<br/>
}</p>
<p>Synchronization statements can be inserted only at points W, X, Y and Z</p>
<p>Which of the following will ensure that the output string never contains a substring of the form 01^n0 or 10^n1 where n is odd?</p>
<ol>
<li><p>P(S) at W, V(S) at X, P(T) at Y, V(T) at Z, S and T initially 1</p></li>
<li><p>P(S) at W, V(T) at X, P(T) at Y, V(S) at Z, S and T initially 1</p></li>
<li><p>P(S) at W, V(S) at X, P(S) at Y, V(S) at Z, S initially 1</p></li>
<li><p>V(S) at W, V(T) at X, P(S) at Y, P(T) at Z, S and T initially 1</p></li>
</ol>
<p><b>Ans.</b>(3).P(S) at W, V(S) at X, P(S) at Y, V(S) at Z, S initially 1</p>
<p>Explanation:</p>
<p> P(S) means wait on semaphore ’S’ and V(S) means signal on semaphore ‘S’. The definition of these functions are :</p>
<p>Wait(S)  {<br/>
   while (i <= 0) ;<br/>
   S-- ; <br/>
}
</p>
<p>Signal(S)  {<br/>
   S++ ;<br/> 
}</p>
<p>Initially S = 1 and T = 0 to support mutual exclusion in process ‘P’ and ‘Q’.</p>
<p>Since, S = 1 , process ‘P’ will be executed and function Wait(S) will decrement the value of ‘S’. So, S = 0 now.</p>
<p>Simultaneously, in process ‘Q’ , T = 0 . Therefore, in process ‘Q’ control will be stuck in while loop till the time process ‘P’ prints ‘00’ and increments the value of ‘T’ by calling function V(T).</p>
<p>While the control is in process ‘Q’, S = 0 and process ‘P’ will be stuck in while loop. Process ‘P’ will not execute till the time process ‘Q’ prints ‘11’ and makes S = 1 by calling function V(S).</p>
<p>Thus, process ‘P’ and ‘Q’ will keep on repeating to give the output ‘00110011 …… ‘ .</p>
<br/><br/>

</body>
</html>
